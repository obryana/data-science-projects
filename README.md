## NLP Classifier for UK Coffee Shops
   *I used a set of UK retail locations and associated category labels to build a natural language processing procedure for finding a solution to heuristic labelling. I created a set of n-grams with the corpus of data and implemented a TF-IDF vectorizer to downweigh commonly used words. I split the data into testing and training sets and performed cross-validation using k-nearest neighbors, Random Forest, and Ridge classifiers.*
   
## Diabetes Classifier
   *I participated in the 2021 Women in Data Science Datathon on Kaggle. This year, we used hospital admissions data to predict the probability that a patient has diabetes. After cleaning the raw data (removing columns with high missingness, excluding outliers, and dropping duplicates), I encoded the categorical features and dropped columns with low correlation to the target variable. Missing values were imputed using the MICE algorithm and the classes were balanced using SMOTE oversampling. Finally, I used eXtreme Gradient Boosting (XGBoost) to classify the outputs achieving a 78% ROC AUC score in training (the highest in the competition was 87%).*
   
## Google FooBar Coding Challenge
   *I completed the Google foobar invitation-only coding challenges using Python. One of these timed challenges required performing matrix calculations without the aid of prebuilt libraries to arrive at the probabilities of various terminal states given an input matrix of state transition possibilities. I implemented this solution using absorbing Markov chains.*

## Logistic Regression Analysis on Heart Disease Prediction
   *Using data from the UCI Machine Learning Repository, I performed a logistic regression to predict the probability of heart disease given various key biomarkers. I balanced the training data using SMOTE oversampling and implemented PCA to account for multicollinearity among the predictors.*

## Walmart Web scrapers
   *Using Python libraries selenium and pandas, I created web scraping scripts to retrieve data from Walmart.com for grocery items sold in various zip codes. The datapoints are appended to a dataframe which is then written to a local file.*


